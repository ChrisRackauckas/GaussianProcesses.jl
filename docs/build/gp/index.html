<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Gaussian Processes · GaussianProcesses.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">GaussianProcesses.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><span class="tocitem">Basic usage</span><ul><li><a class="tocitem" href="../Regression/">Simple GP Regression</a></li><li><a class="tocitem" href="../plotting_gps/">Plotting with GaussianProcesses.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../classification_example/">Binary classification</a></li><li><a class="tocitem" href="../sparse_example/">Sparse GPs</a></li><li><a class="tocitem" href="../mauna_loa/">Time series example with Mauna Loa data</a></li><li><a class="tocitem" href="../poisson_regression/">Poisson Regression example</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li class="is-active"><a class="tocitem" href>Gaussian Processes</a></li><li><a class="tocitem" href="../kernels/">Kernels</a></li><li><a class="tocitem" href="../mean/">Means</a></li><li><a class="tocitem" href="../lik/">Likelihoods</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li><li><a class="tocitem" href="../sparse/">Sparse GPs</a></li><li><a class="tocitem" href="../crossvalidation/">Cross Validation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li class="is-active"><a href>Gaussian Processes</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Gaussian Processes</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/master/docs/src/gp.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Gaussian-Processes-1"><a class="docs-heading-anchor" href="#Gaussian-Processes-1">Gaussian Processes</a><a class="docs-heading-anchor-permalink" href="#Gaussian-Processes-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predict_f-Tuple{GPBase,AbstractArray{T,2} where T}" href="#GaussianProcesses.predict_f-Tuple{GPBase,AbstractArray{T,2} where T}"><code>GaussianProcesses.predict_f</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict_f(gp::GPBase, X::Matrix{Float64}[]; full_cov::Bool = false)</code></pre><p>Return posterior mean and variance of the Gaussian Process <code>gp</code> at specfic points which are given as columns of matrix <code>X</code>. If <code>full_cov</code> is <code>true</code>, the full covariance matrix is returned instead of only variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GP.jl#L57-L63">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.GPE" href="#GaussianProcesses.GPE"><code>GaussianProcesses.GPE</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GPE(x, y, mean, kernel[, logNoise])</code></pre><p>Fit a Gaussian process to a set of training points. The Gaussian process is defined in terms of its user-defined mean and covariance (kernel) functions. As a default it is assumed that the observations are noise free.</p><p><strong>Arguments:</strong></p><ul><li><code>x::AbstractVecOrMat{Float64}</code>: Input observations</li><li><code>y::AbstractVector{Float64}</code>: Output observations</li><li><code>mean::Mean</code>: Mean function</li><li><code>kernel::Kernel</code>: Covariance function</li><li><code>logNoise::Float64</code>: Natural logarithm of the standard deviation for the observation noise. The default is -2.0, which is equivalent to assuming no observation noise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L77-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.GPE-Tuple{}" href="#GaussianProcesses.GPE-Tuple{}"><code>GaussianProcesses.GPE</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">GPE(; mean::Mean = MeanZero(), kernel::Kernel = SE(0.0, 0.0), logNoise::AbstractFloat = -2.0)</code></pre><p>Construct a <a href="#GaussianProcesses.GPE"><code>GPE</code></a> object without observations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L99-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.GP" href="#GaussianProcesses.GP"><code>GaussianProcesses.GP</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">GP(x, y, mean::Mean, kernel::Kernel[, logNoise::AbstractFloat=-2.0])</code></pre><p>Fit a Gaussian process that is defined by its <code>mean</code>, its <code>kernel</code>, and the logarithm <code>logNoise</code> of the standard deviation of its observation noise to a set of training points <code>x</code> and <code>y</code>.</p><p>See also: <a href="#GaussianProcesses.GPE"><code>GPE</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L110-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_target!-Tuple{GPE}" href="#GaussianProcesses.update_target!-Tuple{GPE}"><code>GaussianProcesses.update_target!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_target!(gp::GPE, ...)</code></pre><p>Update the log-posterior</p><div>\[\log p(θ | y) ∝ \log p(y | θ) +  \log p(θ)\]</div><p>of a Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L333-L341">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.GPA-Tuple{AbstractArray{T,2} where T,AbstractArray{#s152,1} where #s152&lt;:Real,GaussianProcesses.Mean,Kernel,Likelihood}" href="#GaussianProcesses.GPA-Tuple{AbstractArray{T,2} where T,AbstractArray{#s152,1} where #s152&lt;:Real,GaussianProcesses.Mean,Kernel,Likelihood}"><code>GaussianProcesses.GPA</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">GPA(x, y, mean, kernel, lik)</code></pre><p>Fit a Gaussian process to a set of training points. The Gaussian process with non-Gaussian observations is defined in terms of its user-defined likelihood function, mean and covaiance (kernel) functions.</p><p>The non-Gaussian likelihood is handled by an approximate method (e.g. Monte Carlo). The latent function values are represented by centered (whitened) variables <span>$f(x) = m(x) + Lv$</span> where <span>$v ∼ N(0, I)$</span> and <span>$LLᵀ = K_θ$</span>.</p><p><strong>Arguments:</strong></p><ul><li><code>x::AbstractVecOrMat{Float64}</code>: Input observations</li><li><code>y::AbstractVector{&lt;:Real}</code>: Output observations</li><li><code>mean::Mean</code>: Mean function</li><li><code>kernel::Kernel</code>: Covariance function</li><li><code>lik::Likelihood</code>: Likelihood function</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L59-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.GP-Tuple{Union{AbstractArray{Float64,1}, AbstractArray{Float64,2}},AbstractArray{#s152,1} where #s152&lt;:Real,GaussianProcesses.Mean,Kernel,Likelihood}" href="#GaussianProcesses.GP-Tuple{Union{AbstractArray{Float64,1}, AbstractArray{Float64,2}},AbstractArray{#s152,1} where #s152&lt;:Real,GaussianProcesses.Mean,Kernel,Likelihood}"><code>GaussianProcesses.GP</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">GP(x, y, mean::Mean, kernel::Kernel, lik::Likelihood)</code></pre><p>Fit a Gaussian process that is defined by its <code>mean</code>, its <code>kernel</code>, and its likelihood function <code>lik</code> to a set of training points <code>x</code> and <code>y</code>.</p><p>See also: <a href="#GaussianProcesses.GPA-Tuple{AbstractArray{T,2} where T,AbstractArray{#s152,1} where #s152&lt;:Real,GaussianProcesses.Mean,Kernel,Likelihood}"><code>GPA</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L85-L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_target!-Tuple{GPA}" href="#GaussianProcesses.update_target!-Tuple{GPA}"><code>GaussianProcesses.update_target!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_target!(gp::GPA, ...)</code></pre><p>Update the log-posterior</p><div>\[\log p(θ, v | y) ∝ \log p(y | v, θ) + \log p(v) + \log p(θ)\]</div><p>of a Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L266-L274">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.ess-Tuple{GPE}" href="#GaussianProcesses.ess-Tuple{GPE}"><code>GaussianProcesses.ess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">ess(gp::GPBase; kwargs...)</code></pre><p>Sample GP hyperparameters using the elliptical slice sampling algorithm described in,</p><p>Murray, Iain, Ryan P. Adams, and David JC MacKay. &quot;Elliptical slice sampling.&quot;  Journal of Machine Learning Research 9 (2010): 541-548.</p><p>Requires hyperparameter priors to be Gaussian.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/mcmc.jl#L88-L97">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.mcmc-Tuple{GPBase}" href="#GaussianProcesses.mcmc-Tuple{GPBase}"><code>GaussianProcesses.mcmc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">mcmc(gp::GPBase; kwargs...)</code></pre><p>Runs Hamiltonian Monte Carlo algorithm for estimating the hyperparameters of Gaussian process <code>GPE</code> and the latent function in the case of <code>GPA</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/mcmc.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.CovarianceStrategy" href="#GaussianProcesses.CovarianceStrategy"><code>GaussianProcesses.CovarianceStrategy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">The abstract CovarianceStrategy type is for types that control how
the covariance matrices and their positive definite representation
are obtained or approximated. See SparseStrategy for examples.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GP.jl#L5-L9">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.make_posdef!-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}" href="#GaussianProcesses.make_posdef!-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>GaussianProcesses.make_posdef!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">make_posdef!(m::Matrix{Float64}, chol_factors::Matrix{Float64})</code></pre><p>Try to encode covariance matrix <code>m</code> as a positive definite matrix. The <code>chol_factors</code> matrix is recycled to store the cholesky decomposition, so as to reduce the number of memory allocations.</p><p>Sometimes covariance matrices of Gaussian processes are positive definite mathematically but have negative eigenvalues numerically. To resolve this issue, small weights are added to the diagonal (and hereby all eigenvalues are raised by that amount mathematically) until all eigenvalues are positive numerically.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GP.jl#L90-L101">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.CovarianceStrategy,PDMats.AbstractPDMat}" href="#GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.CovarianceStrategy,PDMats.AbstractPDMat}"><code>GaussianProcesses.predictMVN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">    predictMVN(xpred::AbstractMatrix, xtrain::AbstractMatrix, ytrain::AbstractVector,
               kernel::Kernel, meanf::Mean, alpha::AbstractVector,
               covstrat::CovarianceStrategy, Ktrain::AbstractPDMat)</code></pre><p>Compute predictions using the standard multivariate normal conditional distribution formulae.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GP.jl#L32-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.AbstractGradientPrecompute" href="#GaussianProcesses.AbstractGradientPrecompute"><code>GaussianProcesses.AbstractGradientPrecompute</code></a> — <span class="docstring-category">Type</span></header><section><div><p>AbstractGradientPrecompute types hold results of     pre-computations of kernel gradients.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L236-L239">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,GaussianProcesses.KernelData,Array{Float64,2},GaussianProcesses.CovarianceStrategy}" href="#GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,GaussianProcesses.KernelData,Array{Float64,2},GaussianProcesses.CovarianceStrategy}"><code>GaussianProcesses.dmll_kern!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dmll_kern!((dmll::AbstractVector, k::Kernel, X::AbstractMatrix, data::KernelData, ααinvcKI::AbstractMatrix))</code></pre><p>Derivative of the marginal log likelihood log p(Y|θ) with respect to the kernel hyperparameters.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L207-L211">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.fit!-Union{Tuple{Y}, Tuple{X}, Tuple{GPE{X,Y,M,K,CS,D,P} where P&lt;:AbstractPDMat where D&lt;:KernelData where CS&lt;:CovarianceStrategy where K&lt;:Kernel where M&lt;:Mean,X,Y}} where Y where X" href="#GaussianProcesses.fit!-Union{Tuple{Y}, Tuple{X}, Tuple{GPE{X,Y,M,K,CS,D,P} where P&lt;:AbstractPDMat where D&lt;:KernelData where CS&lt;:CovarianceStrategy where K&lt;:Kernel where M&lt;:Mean,X,Y}} where Y where X"><code>GaussianProcesses.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fit!(gp::GPE{X,Y}, x::X, y::Y)</code></pre><p>Fit Gaussian process <code>GPE</code> to a training data set consisting of input observations <code>x</code> and output observations <code>y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L122-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.get_ααinvcKI!-Tuple{AbstractArray{T,2} where T,PDMats.AbstractPDMat,Array{T,1} where T}" href="#GaussianProcesses.get_ααinvcKI!-Tuple{AbstractArray{T,2} where T,PDMats.AbstractPDMat,Array{T,1} where T}"><code>GaussianProcesses.get_ααinvcKI!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">get_ααinvcKI!(ααinvcKI::Matrix{Float64}, cK::AbstractPDMat, α::Vector)</code></pre><p>Write <code>ααᵀ - cK⁻¹</code> to <code>ααinvcKI</code> avoiding any memory allocation, where <code>cK</code> and <code>α</code> are the covariance matrix and the alpha vector of a Gaussian process, respectively. Hereby <code>α</code> is defined as <code>cK⁻¹ (Y - μ)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L144-L150">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.initialise_target!-Tuple{GPE}" href="#GaussianProcesses.initialise_target!-Tuple{GPE}"><code>GaussianProcesses.initialise_target!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">initialise_target!(gp::GPE)</code></pre><p>Initialise the log-posterior</p><div>\[\log p(θ | y) ∝ \log p(y | θ) +  \log p(θ)\]</div><p>of a Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L318-L326">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_cK!-Tuple{GPE}" href="#GaussianProcesses.update_cK!-Tuple{GPE}"><code>GaussianProcesses.update_cK!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_cK!(gp::GPE)</code></pre><p>Update the covariance matrix and its Cholesky decomposition of Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L181-L185">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_dmll!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}" href="#GaussianProcesses.update_dmll!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}"><code>GaussianProcesses.update_dmll!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia"> update_dmll!(gp::GPE, ...)</code></pre><p>Update the gradient of the marginal log-likelihood of Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L275-L279">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_mll!-Tuple{GPE}" href="#GaussianProcesses.update_mll!-Tuple{GPE}"><code>GaussianProcesses.update_mll!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_mll!(gp::GPE)</code></pre><p>Modification of initialise_target! that reuses existing matrices to avoid unnecessary memory allocations, which speeds things up significantly.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L190-L194">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_mll_and_dmll!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}" href="#GaussianProcesses.update_mll_and_dmll!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}"><code>GaussianProcesses.update_mll_and_dmll!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_mll_and_dmll!(gp::GPE, ...)</code></pre><p>Update the gradient of the marginal log-likelihood of a Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L307-L312">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_target_and_dtarget!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}" href="#GaussianProcesses.update_target_and_dtarget!-Tuple{GPE,GaussianProcesses.AbstractGradientPrecompute}"><code>GaussianProcesses.update_target_and_dtarget!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_target_and_dtarget!(gp::GPE, ...)</code></pre><p>Update the log-posterior</p><div>\[\log p(θ | y) ∝ \log p(y | θ) +  \log p(θ)\]</div><p>of a Gaussian process <code>gp</code> and its derivative.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPE.jl#L354-L362">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.initialise_ll!-Tuple{GPA}" href="#GaussianProcesses.initialise_ll!-Tuple{GPA}"><code>GaussianProcesses.initialise_ll!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">initialise_ll!(gp::GPA)</code></pre><p>Initialise the log-likelihood of Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L96-L100">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.initialise_target!-Tuple{GPA}" href="#GaussianProcesses.initialise_target!-Tuple{GPA}"><code>GaussianProcesses.initialise_target!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">initialise_target!(gp::GPA)</code></pre><p>Initialise the log-posterior</p><div>\[\log p(θ, v | y) ∝ \log p(y | v, θ) + \log p(v) + \log p(θ)\]</div><p>of a Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L250-L258">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_cK!-Tuple{GPA}" href="#GaussianProcesses.update_cK!-Tuple{GPA}"><code>GaussianProcesses.update_cK!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_cK!(gp::GPA)</code></pre><p>Update the covariance matrix and its Cholesky decomposition of Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L111-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_dll!-Tuple{GPA,GaussianProcesses.AbstractGradientPrecompute}" href="#GaussianProcesses.update_dll!-Tuple{GPA,GaussianProcesses.AbstractGradientPrecompute}"><code>GaussianProcesses.update_dll!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia"> update_dll!(gp::GPA, ...)</code></pre><p>Update the gradient of the log-likelihood of Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L192-L196">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.update_target_and_dtarget!-Tuple{GPA,GaussianProcesses.AbstractGradientPrecompute}" href="#GaussianProcesses.update_target_and_dtarget!-Tuple{GPA,GaussianProcesses.AbstractGradientPrecompute}"><code>GaussianProcesses.update_target_and_dtarget!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">update_target_and_dtarget!(gp::GPA, ...)</code></pre><p>Update the log-posterior</p><div>\[\log p(θ, v | y) ∝ \log p(y | v, θ) + \log p(v) + \log p(θ)\]</div><p>of a Gaussian process <code>gp</code> and its derivative.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/GPA.jl#L288-L296">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.composite_param_names-Tuple{Any,Any}" href="#GaussianProcesses.composite_param_names-Tuple{Any,Any}"><code>GaussianProcesses.composite_param_names</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">composite_param_names(objects, prefix)</code></pre><p>Call <code>get_param_names</code> on each element of <code>objects</code> and prefix the returned name of the element at index <code>i</code> with <code>prefix * i * &#39;_&#39;</code>.</p><p><strong>Examples</strong></p><pre><code class="language-none">julia&gt; GaussianProcesses.get_param_names(ProdKernel(Mat12Iso(1/2, 1/2), SEArd([0.0, 1.0], 0.0)))
5-element Array{Symbol,1}:
 :pk1_ll
 :pk1_lσ
 :pk2_ll_1
 :pk2_ll_2
 :pk2_lσ</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/common.jl#L43-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.map_column_pairs!-Tuple{AbstractArray{T,2} where T,Any,AbstractArray{T,2} where T,AbstractArray{T,2} where T}" href="#GaussianProcesses.map_column_pairs!-Tuple{AbstractArray{T,2} where T,Any,AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>GaussianProcesses.map_column_pairs!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">map_column_pairs!(D::Matrix{Float64}, f, X::Matrix{Float64}[, Y::Matrix{Float64} = X])</code></pre><p>Like <a href="#GaussianProcesses.map_column_pairs-Tuple{Any,AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>map_column_pairs</code></a>, but stores the result in <code>D</code> rather than a new matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/utils.jl#L28-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.map_column_pairs-Tuple{Any,AbstractArray{T,2} where T,AbstractArray{T,2} where T}" href="#GaussianProcesses.map_column_pairs-Tuple{Any,AbstractArray{T,2} where T,AbstractArray{T,2} where T}"><code>GaussianProcesses.map_column_pairs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">map_column_pairs(f, X::Matrix{Float64}[, Y::Matrix{Float64} = X])</code></pre><p>Create a matrix by applying function <code>f</code> to each pair of columns of input matrices <code>X</code> and <code>Y</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/utils.jl#L1-L7">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../poisson_regression/">« Poisson Regression example</a><a class="docs-footer-nextpage" href="../kernels/">Kernels »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 11 December 2019 16:01">Wednesday 11 December 2019</span>. Using Julia version 1.1.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
