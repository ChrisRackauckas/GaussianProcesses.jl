<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Sparse GPs · GaussianProcesses.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">GaussianProcesses.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><span class="tocitem">Basic usage</span><ul><li><a class="tocitem" href="../Regression/">Simple GP Regression</a></li><li><a class="tocitem" href="../plotting_gps/">Plotting with GaussianProcesses.jl</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../classification_example/">Binary classification</a></li><li><a class="tocitem" href="../sparse_example/">Sparse GPs</a></li><li><a class="tocitem" href="../mauna_loa/">Time series example with Mauna Loa data</a></li><li><a class="tocitem" href="../poisson_regression/">Poisson Regression example</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../gp/">Gaussian Processes</a></li><li><a class="tocitem" href="../kernels/">Kernels</a></li><li><a class="tocitem" href="../mean/">Means</a></li><li><a class="tocitem" href="../lik/">Likelihoods</a></li><li><a class="tocitem" href="../optimization/">Optimization</a></li><li class="is-active"><a class="tocitem" href>Sparse GPs</a></li><li><a class="tocitem" href="../crossvalidation/">Cross Validation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li class="is-active"><a href>Sparse GPs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Sparse GPs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/master/docs/src/sparse.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Sparse-GPs-1"><a class="docs-heading-anchor" href="#Sparse-GPs-1">Sparse GPs</a><a class="docs-heading-anchor-permalink" href="#Sparse-GPs-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predict_f-Tuple{GPBase,AbstractArray{T,2} where T,Array{#s270,1} where #s270&lt;:AbstractArray{Int64,1}}" href="#GaussianProcesses.predict_f-Tuple{GPBase,AbstractArray{T,2} where T,Array{#s270,1} where #s270&lt;:AbstractArray{Int64,1}}"><code>GaussianProcesses.predict_f</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict_f(gp::GPBase, X::Matrix{Float64}[; full_cov::Bool = false])</code></pre><p>Return posterior mean and variance of the Gaussian Process <code>gp</code> at specfic points which are given as columns of matrix <code>X</code>. If <code>full_cov</code> is <code>true</code>, the full covariance matrix is returned instead of only variances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L445-L451">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.DeterminTrainCondStrat" href="#GaussianProcesses.DeterminTrainCondStrat"><code>GaussianProcesses.DeterminTrainCondStrat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Deterministic Training Conditional (DTC) covariance strategy.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/determ_train_conditional.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.DeterminTrainCondStrat,PDMats.AbstractPDMat}" href="#GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.DeterminTrainCondStrat,PDMats.AbstractPDMat}"><code>GaussianProcesses.predictMVN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Deterministic Training Conditional (DTC) multivariate normal predictions.

See Quiñonero-Candela and Rasmussen 2005, equations 20b.
    μ_DTC = μ_SoR
    Σ_DTC = Σxx - Qxx + Σ_SoR

where μ_DTC and Σ_DTC are the predictive mean and covariance
functions for the Subset of Regressors approximation.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/determ_train_conditional.jl#L31-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.FullScaleApproxStrat" href="#GaussianProcesses.FullScaleApproxStrat"><code>GaussianProcesses.FullScaleApproxStrat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Fully Independent Training Conditional (FSA) covariance strategy.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L169-L171">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.FullScalePDMat" href="#GaussianProcesses.FullScalePDMat"><code>GaussianProcesses.FullScalePDMat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Positive Definite Matrix for Full Scale Approximation.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L76-L78">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\-Tuple{GaussianProcesses.FullScalePDMat,Any}" href="#Base.:\\-Tuple{GaussianProcesses.FullScalePDMat,Any}"><code>Base.:\</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
where Λ is a diagonal matrix (here given by σ²I + diag(Kff - Qff))
The Woodbury matrix identity gives
    (A+UCV)⁻¹ = A⁻¹ - A⁻¹ U(C⁻¹ + V A⁻¹ U)⁻¹ V A⁻¹
which we use here with
    A ← Λ
    U = Kuf&#39;
    V = Kuf
    C = Kuu⁻¹
which gives
    Σ⁻¹ = Λ⁻¹ - Λ⁻¹ Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf Λ⁻¹
        = Λ⁻¹ - Λ⁻¹ Kuf&#39;(        ΣQR       )⁻¹ Kuf Λ⁻¹</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L88-L102">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.FullScaleApproxStrat}" href="#GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.FullScaleApproxStrat}"><code>GaussianProcesses.dmll_kern!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dmll_kern!(dmll::AbstractVector, kernel::Kernel, X::AbstractMatrix, cK::AbstractPDMat, kerneldata::KernelData,                     alpha::AbstractVector, Kuu, Kuf, Kuu⁻¹Kuf, Kuu⁻¹KufΣ⁻¹y, Σ⁻¹Kfu, ∂Kuu, ∂Kuf,                     covstrat::FullScaleApproxStrat) Derivative of the log likelihood under the Fully Independent Training Conditional (fsa) approximation.</p><p>Helpful reference: Vanhatalo, Jarno, and Aki Vehtari.                    &quot;Sparse log Gaussian processes via MCMC for spatial epidemiology.&quot;                    In Gaussian processes in practice, pp. 73-89. 2007.</p><p>Generally, for a multivariate normal with zero mean     ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)                     ╰───────────────╯     ╰──────────╯                            <code>V</code>                 <code>T</code></p><p>where Σ = Kff + σ²I.</p><p>Notation: <code>f</code> is the observations, <code>u</code> is the inducing points.           ∂X stands for ∂X/∂θ, where θ is the kernel hyperparameters.</p><p>In the case of the FSA approximation, we have     Σ = Λ + Qff     The second component gives     ∂(Qff) = ∂(Kfu Kuu⁻¹ Kuf)     which is used by the gradient function for the subset of regressors approximation,     and so I don&#39;t repeat it here.</p><pre><code class="language-none">for ∂Λ we have (with `i` indexing each block)
Λi = Ki - Qi + σ²I
   = Ki - Kui&#39; Kuu⁻¹ Kui + σ²
∂Λi = ∂Ki - Kui&#39; ∂(Kuu⁻¹) Kui - 2 ∂Kui&#39; Kuu⁻¹ Kui
    = ∂Ki + Kui&#39; Kuu⁻¹ ∂(Kuu) Kuu⁻¹ Kui - 2 ∂Kui&#39; Kuu⁻¹ Kui</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L239-L271">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.FullScaleApproxStrat}" href="#GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.FullScaleApproxStrat}"><code>GaussianProcesses.dmll_noise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dmll_noise(gp::GPE, precomp::SoRPrecompute, covstrat::FullScaleApproxStrat)</code></pre><p>∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)</p><p>∂Σ = I for derivative wrt σ², so ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ Σ⁻¹ y - 1/2 tr(Σ⁻¹)             = 1/2[ dot(α,α) - tr(Σ⁻¹) ]</p><p>We have:     Σ⁻¹ = Λ⁻¹ - Λ⁻² Kuf&#39;(        ΣQR       )⁻¹ Kuf Use the identity tr(A&#39;A) = dot(A,A) to get:     tr(Σ⁻¹) = tr(Λ⁻¹) - dot(Lk, Lk) . where     Lk ≡ ΣQR^(-1/2) Kuf Λ⁻¹</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L326-L341">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,Array{#s270,1} where #s270&lt;:AbstractArray{Int64,1},AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.FullScaleApproxStrat,GaussianProcesses.FullScalePDMat}" href="#GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,Array{#s270,1} where #s270&lt;:AbstractArray{Int64,1},AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.FullScaleApproxStrat,GaussianProcesses.FullScalePDMat}"><code>GaussianProcesses.predictMVN</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predictMVN(xpred::AbstractMatrix, xtrain::AbstractMatrix, ytrain::AbstractVector,                     kernel::Kernel, meanf::Mean, logNoise::Real,                     alpha::AbstractVector,                     covstrat::FullScaleApproxStrat, Ktrain::FullScalePDMat)     See Quiñonero-Candela and Rasmussen 2005, equations 24b.     Some derivations can be found below that are not spelled out in the paper.</p><pre><code class="language-none">Notation: Qab = Kau Kuu⁻¹ Kub
          ΣQR = Kuu + σ⁻² Kuf Kuf&#39;

          x: prediction (test) locations
          f: training (observed) locations
          u: inducing point locations

We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
By Woodbury
    Σ⁻¹ = Λ⁻¹ - Λ⁻² Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf
        = Λ⁻¹ - Λ⁻² Kuf&#39;(        ΣQR       )⁻¹ Kuf

The predictive mean can be derived (assuming zero mean function for simplicity)
μ = (Qxf+Λxf) (Qff + Λff)⁻¹ y
  = Qxf (Qff + Λff)⁻¹ y   + Λxf (Qff + Λff)⁻¹ y
    ╰─────────────────╯
        same as FITC
  = Kxu ΣQR⁻¹ Kuf Λff⁻¹ y + Λxf (Qff + Λff)⁻¹ y
       ╰────────────────╯       ╰─────────────╯
          ≡ alpha_u                ≡ alpha

Similarly for the posterior predictive covariance:
Σ = Σxx - (Qxf+Λxf) (Qff + Λff)⁻¹ (Qxf+Λxf)&#39;
  = Σxx - Kxu ΣQR⁻¹ Kuf Λ⁻¹ Qxf&#39;                # substituting result from μ
  = Σxx - Kxu ΣQR⁻¹  Kuf Λ⁻¹ Kfu Kuu⁻¹ Kux      # definition of Qxf
  = Σxx - Kxu ΣQR⁻¹ (ΣQR - Kuu) Kuu⁻¹ Kux       # using definition of ΣQR
  = Σxx - Kxu Kuu⁻¹ Kux + Kxu ΣQR⁻¹ Kux         # expanding
  = Σxx - Qxx           + Kxu ΣQR⁻¹ Kux         # definition of Qxx</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L371-L408">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.trinv-Tuple{GaussianProcesses.BlockDiagPDMat}" href="#GaussianProcesses.trinv-Tuple{GaussianProcesses.BlockDiagPDMat}"><code>GaussianProcesses.trinv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trinv(a::BlockDiagPDMat)</code></pre><p>Trace of the inverse of a block diagonal positive definite matrix.</p><p>This is obtained as the sum of the traces of the inverse of each block.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L51-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.trinv-Tuple{PDMats.AbstractPDMat}" href="#GaussianProcesses.trinv-Tuple{PDMats.AbstractPDMat}"><code>GaussianProcesses.trinv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trinv(pd::AbstractPDMat)</code></pre><p>Trace of the inverse of a positive definite matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L41-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.trinvAB-Tuple{GaussianProcesses.FullScalePDMat,LinearAlgebra.Diagonal}" href="#GaussianProcesses.trinvAB-Tuple{GaussianProcesses.FullScalePDMat,LinearAlgebra.Diagonal}"><code>GaussianProcesses.trinvAB</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trinvAB(A::FullScalePDMat, B::Diagonal)

Computes tr(A⁻¹ B) efficiently under the FSA approximation:
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ

Derivation:
    tr(Σ⁻¹ B) = tr[ (Λ⁻¹ - Λ⁻² Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf) B ]
              = tr(Λ⁻¹ B) - tr( Λ⁻¹ Kuf&#39; ΣQR⁻¹ Kuf Λ⁻¹ B )
              = tr(Λ⁻¹ B) - tr( Λ⁻¹ Kuf&#39; ΣQR^(-1/2) ΣQR^(-1/2) Kuf Λ⁻¹ B )
                                                    ╰────────────────╯
                                                        ≡ L&#39;
              = tr(Λ⁻¹ B) - tr(L*L&#39;*B)
              = tr(Λ⁻¹ B) - dot(L, B*L)

See also: [``](@ref).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L108-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.logdet-Tuple{GaussianProcesses.FullScalePDMat}" href="#LinearAlgebra.logdet-Tuple{GaussianProcesses.FullScalePDMat}"><code>LinearAlgebra.logdet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">The matrix determinant lemma states that
    logdet(A+UWV&#39;) = logdet(W⁻¹ + V&#39;A⁻¹U) + logdet(W) + logdet(A)
So for
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
    logdet(Σ) = logdet(Kuu + Kuf Λ⁻¹ Kuf&#39;)       + logdet(Kuu⁻¹) + logdet(Λ)
              = logdet(        ΣQR             ) - logdet(Kuu)   + logdet(Λ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L132-L139">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.tr-Tuple{GaussianProcesses.FullScalePDMat}" href="#LinearAlgebra.tr-Tuple{GaussianProcesses.FullScalePDMat}"><code>LinearAlgebra.tr</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tr(a::FullScalePDMat)

Trace of the FSA approximation to the covariance matrix:

tr(Σ) = tr(Kuf&#39; Kuu⁻¹ Kuf + Λ)
      = tr(Kuf&#39; Kuu⁻¹ Kuf) + tr(Λ)
      = tr(Kuf&#39; Kuu^{-1/2} Kuu^{-1/2} Kuf) + tr(Λ)
                          ╰──────────────╯
                             ≡  Lk
      = dot(Lk, Lk) + sum(diag(Λ))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/full_scale_approximation.jl#L151-L162">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.FullyIndepPDMat" href="#GaussianProcesses.FullyIndepPDMat"><code>GaussianProcesses.FullyIndepPDMat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Positive Definite Matrix for Fully Independent Training Conditional approximation.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L5-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.FullyIndepStrat" href="#GaussianProcesses.FullyIndepStrat"><code>GaussianProcesses.FullyIndepStrat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Fully Independent Training Conditional (FITC) covariance strategy.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L108-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\-Tuple{GaussianProcesses.FullyIndepPDMat,Any}" href="#Base.:\\-Tuple{GaussianProcesses.FullyIndepPDMat,Any}"><code>Base.:\</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
where Λ is a diagonal matrix (here given by σ²I + diag(Kff - Qff))
The Woodbury matrix identity gives
    (A+UCV)⁻¹ = A⁻¹ - A⁻¹ U(C⁻¹ + V A⁻¹ U)⁻¹ V A⁻¹
which we use here with
    A ← Λ
    U = Kuf&#39;
    V = Kuf
    C = Kuu⁻¹
which gives
    Σ⁻¹ = Λ⁻¹ - Λ⁻² Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf
        = Λ⁻¹ - Λ⁻² Kuf&#39;(        ΣQR       )⁻¹ Kuf</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L17-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.FullyIndepStrat}" href="#GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.FullyIndepStrat}"><code>GaussianProcesses.dmll_kern!</code></a> — <span class="docstring-category">Method</span></header><section><div><p>dmll_kern!(dmll::AbstractVector, kernel::Kernel, X::AbstractMatrix, cK::AbstractPDMat, kerneldata::KernelData,                     alpha::AbstractVector, Kuu, Kuf, Kuu⁻¹Kuf, Kuu⁻¹KufΣ⁻¹y, Σ⁻¹Kfu, ∂Kuu, ∂Kuf,                     covstrat::FullyIndepStrat) Derivative of the log likelihood under the Fully Independent Training Conditional (FITC) approximation.</p><p>Helpful reference: Vanhatalo, Jarno, and Aki Vehtari.                    &quot;Sparse log Gaussian processes via MCMC for spatial epidemiology.&quot;                    In Gaussian processes in practice, pp. 73-89. 2007.</p><p>Generally, for a multivariate normal with zero mean     ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)                     ╰───────────────╯     ╰──────────╯                            <code>V</code>                 <code>T</code></p><p>where Σ = Kff + σ²I.</p><p>Notation: <code>f</code> is the observations, <code>u</code> is the inducing points.           ∂X stands for ∂X/∂θ, where θ is the kernel hyperparameters.</p><p>In the case of the FITC approximation, we have     Σ = Λ + Qff     The second component gives     ∂(Qff) = ∂(Kfu Kuu⁻¹ Kuf)     which is used by the gradient function for the subset of regressors approximation,     and so I don&#39;t repeat it here.</p><pre><code class="language-none">the ith element of diag(Kff-Qff) is
Λi = Kii - Qii + σ²
   = Kii - Kui&#39; Kuu⁻¹ Kui + σ²
∂Λi = ∂Kii - Kui&#39; ∂(Kuu⁻¹) Kui - 2 ∂Kui&#39; Kuu⁻¹ Kui
    = ∂Kii + Kui&#39; Kuu⁻¹ ∂(Kuu) Kuu⁻¹ Kui - 2 ∂Kui&#39; Kuu⁻¹ Kui</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L166-L198">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.FullyIndepStrat}" href="#GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.FullyIndepStrat}"><code>GaussianProcesses.dmll_noise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dmll_noise(gp::GPE, precomp::SoRPrecompute, covstrat::FullyIndepStrat)</code></pre><p>∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)</p><p>∂Σ = I for derivative wrt σ², so ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ Σ⁻¹ y - 1/2 tr(Σ⁻¹)             = 1/2[ dot(α,α) - tr(Σ⁻¹) ]</p><p>We have:     Σ⁻¹ = Λ⁻¹ - Λ⁻² Kuf&#39;(        ΣQR       )⁻¹ Kuf Use the identity tr(A&#39;A) = dot(A,A) to get:     tr(Σ⁻¹) = tr(Λ⁻¹) - dot(Lk, Lk) . where     Lk ≡ ΣQR^(-1/2) Kuf Λ⁻¹</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L242-L257">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.FullyIndepStrat,GaussianProcesses.FullyIndepPDMat}" href="#GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.FullyIndepStrat,GaussianProcesses.FullyIndepPDMat}"><code>GaussianProcesses.predictMVN</code></a> — <span class="docstring-category">Method</span></header><section><div><p>predictMVN(xpred::AbstractMatrix, xtrain::AbstractMatrix, ytrain::AbstractVector,                     kernel::Kernel, meanf::Mean, logNoise::Real,                     alpha::AbstractVector,                     covstrat::FullyIndepStrat, Ktrain::FullyIndepPDMat)     See Quiñonero-Candela and Rasmussen 2005, equations 24b.     Some derivations can be found below that are not spelled out in the paper.</p><pre><code class="language-none">Notation: Qab = Kau Kuu⁻¹ Kub
          ΣQR = Kuu + σ⁻² Kuf Kuf&#39;

          x: prediction (test) locations
          f: training (observed) locations
          u: inducing point locations

We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
By Woodbury
    Σ⁻¹ = Λ⁻¹ - Λ⁻² Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf
        = Λ⁻¹ - Λ⁻² Kuf&#39;(        ΣQR       )⁻¹ Kuf

The predictive mean can be derived (assuming zero mean function for simplicity)
μ = Qxf (Qff + Λ)⁻¹ y
  = Kxu Kuu⁻¹ Kuf [Λ⁻¹ - Λ⁻² Kuf&#39; ΣQR⁻¹ Kuf] y   # see Woodbury formula above.
  = Kxu Kuu⁻¹ [ΣQR - Kuf Λ⁻¹ Kfu] ΣQR⁻¹ Kuf Λ⁻¹ y # factoring out common terms
  = Kxu Kuu⁻¹ [Kuu] ΣQR⁻¹ Kuf Λ⁻¹ y               # using definition of ΣQR
  = Kxu ΣQR⁻¹ Kuf Λ⁻¹ y                           # matches equation 16b

Similarly for the posterior predictive covariance:
Σ = Σxx - Qxf (Qff + Λ)⁻¹ Qxf&#39;
  = Σxx - Kxu ΣQR⁻¹ Kuf Λ⁻¹ Qxf&#39;                # substituting result from μ
  = Σxx - Kxu ΣQR⁻¹  Kuf Λ⁻¹ Kfu Kuu⁻¹ Kux      # definition of Qxf
  = Σxx - Kxu ΣQR⁻¹ (ΣQR - Kuu) Kuu⁻¹ Kux       # using definition of ΣQR
  = Σxx - Kxu Kuu⁻¹ Kux + Kxu ΣQR⁻¹ Kux         # expanding
  = Σxx - Qxx           + Kxu ΣQR⁻¹ Kux         # definition of Qxx</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L285-L320">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.trinvAB-Tuple{GaussianProcesses.FullyIndepPDMat,LinearAlgebra.Diagonal}" href="#GaussianProcesses.trinvAB-Tuple{GaussianProcesses.FullyIndepPDMat,LinearAlgebra.Diagonal}"><code>GaussianProcesses.trinvAB</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trinvAB(A::FullyIndepPDMat, B::Diagonal)

Computes tr(A⁻¹ B) efficiently under the FITC approximation:
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ

Derivation:
    tr(Σ⁻¹ B) = tr[ (Λ⁻¹ - Λ⁻² Kuf&#39;(Kuu + Kuf Λ⁻¹ Kuf&#39;)⁻¹ Kuf) B ]
              = tr(Λ⁻¹ B) - tr( Λ⁻¹ Kuf&#39; ΣQR⁻¹ Kuf Λ⁻¹ B )
              = tr(Λ⁻¹ B) - tr( Λ⁻¹ Kuf&#39; ΣQR^(-1/2) ΣQR^(-1/2) Kuf Λ⁻¹ B )
                                                    ╰────────────────╯
                                                        ≡ L
              = tr(Λ⁻¹ B) - tr(L&#39;*L*B)
              = tr(Λ⁻¹ B) - dot(L, L*B)

See also: [``](@ref).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L45-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.trinvAB-Tuple{PDMats.AbstractPDMat,Any}" href="#GaussianProcesses.trinvAB-Tuple{PDMats.AbstractPDMat,Any}"><code>GaussianProcesses.trinvAB</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">trinvAB(A::AbstractPDMat, B)

Computes tr(A⁻¹ B).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L37-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.logdet-Tuple{GaussianProcesses.FullyIndepPDMat}" href="#LinearAlgebra.logdet-Tuple{GaussianProcesses.FullyIndepPDMat}"><code>LinearAlgebra.logdet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">The matrix determinant lemma states that
    logdet(A+UWV&#39;) = logdet(W⁻¹ + V&#39;A⁻¹U) + logdet(W) + logdet(A)
So for
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + Λ
    logdet(Σ) = logdet(Kuu + Kuf Λ⁻¹ Kuf&#39;)       + logdet(Kuu⁻¹) + logdet(Λ)
              = logdet(        ΣQR             ) - logdet(Kuu)   + logdet(Λ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L68-L75">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.tr-Tuple{GaussianProcesses.FullyIndepPDMat}" href="#LinearAlgebra.tr-Tuple{GaussianProcesses.FullyIndepPDMat}"><code>LinearAlgebra.tr</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">tr(a::FullyIndepPDMat)

Trace of the FITC approximation to the covariance matrix:

tr(Σ) = tr(Kuf&#39; Kuu⁻¹ Kuf + Λ)
      = tr(Kuf&#39; Kuu⁻¹ Kuf) + tr(Λ)
      = tr(Kuf&#39; Kuu^{-1/2} Kuu^{-1/2} Kuf) + tr(Λ)
                          ╰──────────────╯
                             ≡  Lk
      = dot(Lk, Lk) + sum(diag(Λ))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/fully_indep_train_conditional.jl#L90-L101">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.SubsetOfRegsPDMat" href="#GaussianProcesses.SubsetOfRegsPDMat"><code>GaussianProcesses.SubsetOfRegsPDMat</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Subset of Regressors sparse positive definite matrix.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L4-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.:\\-Tuple{GaussianProcesses.SubsetOfRegsPDMat,Any}" href="#Base.:\\-Tuple{GaussianProcesses.SubsetOfRegsPDMat,Any}"><code>Base.:\</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + σ²I
By Woodbury
    Σ⁻¹ = σ⁻²I - σ⁻⁴ Kuf&#39;(Kuu + σ⁻² Kuf Kuf&#39;)⁻¹ Kuf
        = σ⁻²I - σ⁻⁴ Kuf&#39;(       ΣQR        )⁻¹ Kuf</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L42-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.SubsetOfRegsStrategy}" href="#GaussianProcesses.dmll_kern!-Tuple{AbstractArray{T,1} where T,Kernel,AbstractArray{T,2} where T,PDMats.AbstractPDMat,GaussianProcesses.SparseKernelData,AbstractArray{T,1} where T,Any,Any,Any,Any,Any,Any,Any,GaussianProcesses.SubsetOfRegsStrategy}"><code>GaussianProcesses.dmll_kern!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dmll_kern!(dmll::AbstractVector, kernel::Kernel, X::AbstractMatrix, cK::SubsetOfRegsPDMat, kerneldata::KernelData, ααinvcKI::AbstractMatrix, covstrat::SubsetOfRegsStrategy)</code></pre><p>Derivative of the log likelihood under the Subset of Regressors (SoR) approximation.</p><p>Helpful reference: Vanhatalo, Jarno, and Aki Vehtari.                    &quot;Sparse log Gaussian processes via MCMC for spatial epidemiology.&quot;                    In Gaussian processes in practice, pp. 73-89. 2007.</p><p>Generally, for a multivariate normal with zero mean     ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)                     ╰───────────────╯     ╰──────────╯                            <code>V</code>                 <code>T</code></p><p>where Σ = Kff + σ²I.</p><p>Notation: <code>f</code> is the observations, <code>u</code> is the inducing points.           ∂X stands for ∂X/∂θ, where θ is the kernel hyperparameters.</p><p>In the SoR approximation, we replace Kff with Qff = Kfu Kuu⁻¹ Kuf</p><p>∂Σ = ∂(Qff) = ∂(Kfu Kuu⁻¹ Kuf)             = ∂(Kfu) Kuu⁻¹ Kuf + Kfu ∂(Kuu⁻¹) Kuf + Kfu Kuu⁻¹ ∂(Kuf)</p><p>∂(Kuu⁻¹) = -Kuu⁻¹ ∂(Kuu) Kuu⁻¹  ––––^</p><p>Also have pre-computed α = Σ⁻¹ y, so <code>V</code> can now be computed efficiency (O(nm²) I think…) by careful ordering of the matrix multiplication steps.</p><p>For <code>T</code>, we use the identity tr(AB) = dot(A&#39;,B): tr(Σ⁻¹ ∂Σ) = 2 tr(Σ⁻¹ ∂(Kfu) Kuu⁻¹ Kuf) + tr(Σ⁻¹ Kfu ∂(Kuu⁻¹) Kuf)            = 2 dot((Σ⁻¹ ∂(Kfu))&#39;, Kuu⁻¹ Kuf) - tr(Σ⁻¹ Kfu Kuu⁻¹ ∂Kuu Kuu⁻¹ Kuf)            = 2 dot((Σ⁻¹ ∂(Kfu))&#39;, Kuu⁻¹ Kuf) - dot((Σ⁻¹ Kfu)&#39;, Kuu⁻¹ ∂Kuu Kuu⁻¹ Kuf) which again is computed in O(nm²).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L180-L214">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.SubsetOfRegsStrategy}" href="#GaussianProcesses.dmll_noise-Tuple{GPE,GaussianProcesses.SoRPrecompute,GaussianProcesses.SubsetOfRegsStrategy}"><code>GaussianProcesses.dmll_noise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">dmll_noise(gp::GPE, precomp::SoRPrecompute)</code></pre><p>∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ ∂Σ Σ⁻¹ y - 1/2 tr(Σ⁻¹ ∂Σ)</p><p>∂Σ = I for derivative wrt σ², so ∂logp(Y|θ) = 1/2 y&#39; Σ⁻¹ Σ⁻¹ y - 1/2 tr(Σ⁻¹)             = 1/2[ dot(α,α) - tr(Σ⁻¹) ]</p><p>Σ⁻¹ = σ⁻²I - σ⁻⁴ Kuf&#39;(Kuu + σ⁻² Kuf Kuf&#39;)⁻¹ Kuf     = σ⁻²I - σ⁻⁴ Kuf&#39;(       ΣQR        )⁻¹ Kuf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L157-L168">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.get_alpha_u-Tuple{GaussianProcesses.SubsetOfRegsPDMat,AbstractArray{T,2} where T,AbstractArray{T,1} where T,GaussianProcesses.Mean}" href="#GaussianProcesses.get_alpha_u-Tuple{GaussianProcesses.SubsetOfRegsPDMat,AbstractArray{T,2} where T,AbstractArray{T,1} where T,GaussianProcesses.Mean}"><code>GaussianProcesses.get_alpha_u</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">alpha_u(Ktrain::SubsetOfRegsPDMat, xtrain::AbstractMatrix, ytrain::AbstractVector, m::Mean)

ΣQR⁻¹ Kuf Λ⁻¹ (y-μ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L251-L255">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.SubsetOfRegsStrategy,PDMats.AbstractPDMat}" href="#GaussianProcesses.predictMVN-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T,AbstractArray{T,1} where T,Kernel,GaussianProcesses.Mean,AbstractArray{T,1} where T,GaussianProcesses.SubsetOfRegsStrategy,PDMats.AbstractPDMat}"><code>GaussianProcesses.predictMVN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">See Quiñonero-Candela and Rasmussen 2005, equations 16b.
Some derivations can be found below that are not spelled out in the paper.

Notation: Qab = Kau Kuu⁻¹ Kub
          ΣQR = Kuu + σ⁻² Kuf Kuf&#39;

          x: prediction (test) locations
          f: training (observed) locations
          u: inducing point locations

We have
    Σ ≈ Kuf&#39; Kuu⁻¹ Kuf + σ²I
By Woodbury
    Σ⁻¹ = σ⁻²I - σ⁻⁴ Kuf&#39;(Kuu + σ⁻² Kuf Kuf&#39;)⁻¹ Kuf
        = σ⁻²I - σ⁻⁴ Kuf&#39;(       ΣQR        )⁻¹ Kuf

The predictive mean can be derived (assuming zero mean function for simplicity)
μ = Qxf (Qff + σ²I)⁻¹ y
  = Kxu Kuu⁻¹ Kuf [σ⁻²I - σ⁻⁴ Kuf&#39; ΣQR⁻¹ Kuf] y   # see Woodbury formula above.
  = σ⁻² Kxu Kuu⁻¹ [ΣQR - σ⁻² Kuf Kfu] ΣQR⁻¹ Kuf y # factoring out common terms
  = σ⁻² Kxu Kuu⁻¹ [Kuu] ΣQR⁻¹ Kuf y               # using definition of ΣQR
  = σ⁻² Kxu ΣQR⁻¹ Kuf y                           # matches equation 16b

Similarly for the posterior predictive covariance:
Σ = Qxx - Qxf (Qff + σ²I)⁻¹ Qxf&#39;
  = Qxx - σ⁻² Kxu ΣQR⁻¹ Kuf Qxf&#39;                # substituting result from μ
  = Qxx - σ⁻² Kxu ΣQR⁻¹  Kuf Kfu    Kuu⁻¹ Kux   # definition of Qxf
  = Qxx -     Kxu ΣQR⁻¹ (ΣQR - Kuu) Kuu⁻¹ Kux   # using definition of ΣQR
  = Qxx - Kxu Kuu⁻¹ Kux + Kxu ΣQR⁻¹ Kux         # expanding
  = Qxx - Qxx           + Kxu ΣQR⁻¹ Kux         # definition of Qxx
  = Kxu ΣQR⁻¹ Kux                               # simplifying</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/STOR-i/GaussianProcesses.jl/blob/1bcdf2dd8a988b91b0661e7ad1504d5fa66d9e65/src/sparse/subsetofregressors.jl#L265-L297">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../optimization/">« Optimization</a><a class="docs-footer-nextpage" href="../crossvalidation/">Cross Validation »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 11 December 2019 16:01">Wednesday 11 December 2019</span>. Using Julia version 1.1.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
